{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ES-RNN_notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUglM43+1JZzInZwa3ei96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/d-maniatakos/thesis/blob/main/ES_RNN_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ES-RNN"
      ],
      "metadata": {
        "id": "tEkq37hYHO0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "hQ2hn_qlHRyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wru2St9RFR31"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from ESRNN import ESRNN\n",
        "from ESRNN.m4_data import prepare_m4_data\n",
        "from ESRNN.utils_evaluation import evaluate_prediction_owa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('AirPassengers.csv')\n",
        "df.index = pd.date_range(start='1949-01', end='1961-01', freq='M')\n",
        "df = df['#Passengers']\n",
        "\n",
        "y_df = df.to_frame().reset_index()\n",
        "y_df.columns=['ds', 'y']\n",
        "y_df.index.name = 'unique_id'\n",
        "y_df = y_df.reset_index()\n",
        "y_df['unique_id'] = 'Y1'\n",
        "y_df['y'] = y_df['y'].astype(float)\n",
        "\n",
        "x_df = y_df.copy()\n",
        "x_df.columns=['unique_id','ds', 'x']\n",
        "x_df['x'] = x_df['x'].astype('str')\n",
        "\n",
        "x_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_MLKGZAIsJ0",
        "outputId": "39ab062e-bb70-4884-861f-857335a393a5"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unique_id            object\n",
              "ds           datetime64[ns]\n",
              "x                    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Instantiate model\n",
        "model = ESRNN(max_epochs=100, freq_of_test=5, batch_size=4, learning_rate=1e-4,\n",
        "              per_series_lr_multip=0.8, lr_scheduler_step_size=10,\n",
        "              lr_decay=0.1, gradient_clipping_threshold=50,\n",
        "              rnn_weight_decay=0.0, level_variability_penalty=100,\n",
        "              testing_percentile=50, training_percentile=50,\n",
        "              ensemble=False, max_periods=25, seasonality=[],\n",
        "              input_size=4, output_size=6,\n",
        "              cell_type='LSTM', state_hsize=40,\n",
        "              dilations=[[1], [6]], add_nl_layer=False,\n",
        "              random_seed=1, device='cpu')\n",
        "\n",
        "# Fit model\n",
        "# If y_test_df is provided the model\n",
        "# will evaluate predictions on\n",
        "# this set every freq_test epochs\n",
        "model.fit(x_df, y_df)\n",
        "\n",
        "# Predict on test set\n",
        "y_hat_df = model.predict(x_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sfTWG5w5HqNu",
        "outputId": "194e5883-6a55-4097-eeb9-4a464720f49c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infered frequency: M\n",
            "=============== Training ESRNN  ===============\n",
            "\n",
            "========= Epoch 0 finished =========\n",
            "Training time: 0.08789\n",
            "Training loss (50 prc): 0.65995\n",
            "========= Epoch 1 finished =========\n",
            "Training time: 0.08268\n",
            "Training loss (50 prc): 0.65961\n",
            "========= Epoch 2 finished =========\n",
            "Training time: 0.13574\n",
            "Training loss (50 prc): 0.65927\n",
            "========= Epoch 3 finished =========\n",
            "Training time: 0.14571\n",
            "Training loss (50 prc): 0.65894\n",
            "========= Epoch 4 finished =========\n",
            "Training time: 0.13941\n",
            "Training loss (50 prc): 0.65860\n",
            "========= Epoch 5 finished =========\n",
            "Training time: 0.15507\n",
            "Training loss (50 prc): 0.65826\n",
            "========= Epoch 6 finished =========\n",
            "Training time: 0.16576\n",
            "Training loss (50 prc): 0.65792\n",
            "========= Epoch 7 finished =========\n",
            "Training time: 0.15912\n",
            "Training loss (50 prc): 0.65759\n",
            "========= Epoch 8 finished =========\n",
            "Training time: 0.14619\n",
            "Training loss (50 prc): 0.65727\n",
            "========= Epoch 9 finished =========\n",
            "Training time: 0.14625\n",
            "Training loss (50 prc): 0.65696\n",
            "========= Epoch 10 finished =========\n",
            "Training time: 0.20692\n",
            "Training loss (50 prc): 0.65666\n",
            "========= Epoch 11 finished =========\n",
            "Training time: 0.13686\n",
            "Training loss (50 prc): 0.65660\n",
            "========= Epoch 12 finished =========\n",
            "Training time: 0.15321\n",
            "Training loss (50 prc): 0.65654\n",
            "========= Epoch 13 finished =========\n",
            "Training time: 0.13655\n",
            "Training loss (50 prc): 0.65648\n",
            "========= Epoch 14 finished =========\n",
            "Training time: 0.19507\n",
            "Training loss (50 prc): 0.65641\n",
            "========= Epoch 15 finished =========\n",
            "Training time: 0.13428\n",
            "Training loss (50 prc): 0.65635\n",
            "========= Epoch 16 finished =========\n",
            "Training time: 0.08668\n",
            "Training loss (50 prc): 0.65629\n",
            "========= Epoch 17 finished =========\n",
            "Training time: 0.08591\n",
            "Training loss (50 prc): 0.65623\n",
            "========= Epoch 18 finished =========\n",
            "Training time: 0.07838\n",
            "Training loss (50 prc): 0.65617\n",
            "========= Epoch 19 finished =========\n",
            "Training time: 0.08951\n",
            "Training loss (50 prc): 0.65611\n",
            "========= Epoch 20 finished =========\n",
            "Training time: 0.07928\n",
            "Training loss (50 prc): 0.65605\n",
            "========= Epoch 21 finished =========\n",
            "Training time: 0.07832\n",
            "Training loss (50 prc): 0.65602\n",
            "========= Epoch 22 finished =========\n",
            "Training time: 0.08428\n",
            "Training loss (50 prc): 0.65598\n",
            "========= Epoch 23 finished =========\n",
            "Training time: 0.08775\n",
            "Training loss (50 prc): 0.65595\n",
            "========= Epoch 24 finished =========\n",
            "Training time: 0.0878\n",
            "Training loss (50 prc): 0.65591\n",
            "========= Epoch 25 finished =========\n",
            "Training time: 0.09093\n",
            "Training loss (50 prc): 0.65588\n",
            "========= Epoch 26 finished =========\n",
            "Training time: 0.08287\n",
            "Training loss (50 prc): 0.65585\n",
            "========= Epoch 27 finished =========\n",
            "Training time: 0.08092\n",
            "Training loss (50 prc): 0.65581\n",
            "========= Epoch 28 finished =========\n",
            "Training time: 0.08987\n",
            "Training loss (50 prc): 0.65578\n",
            "========= Epoch 29 finished =========\n",
            "Training time: 0.08084\n",
            "Training loss (50 prc): 0.65574\n",
            "========= Epoch 30 finished =========\n",
            "Training time: 0.08118\n",
            "Training loss (50 prc): 0.65571\n",
            "========= Epoch 31 finished =========\n",
            "Training time: 0.0862\n",
            "Training loss (50 prc): 0.65568\n",
            "========= Epoch 32 finished =========\n",
            "Training time: 0.08115\n",
            "Training loss (50 prc): 0.65565\n",
            "========= Epoch 33 finished =========\n",
            "Training time: 0.08476\n",
            "Training loss (50 prc): 0.65562\n",
            "========= Epoch 34 finished =========\n",
            "Training time: 0.09465\n",
            "Training loss (50 prc): 0.65559\n",
            "========= Epoch 35 finished =========\n",
            "Training time: 0.08254\n",
            "Training loss (50 prc): 0.65557\n",
            "========= Epoch 36 finished =========\n",
            "Training time: 0.08999\n",
            "Training loss (50 prc): 0.65554\n",
            "========= Epoch 37 finished =========\n",
            "Training time: 0.08977\n",
            "Training loss (50 prc): 0.65551\n",
            "========= Epoch 38 finished =========\n",
            "Training time: 0.08263\n",
            "Training loss (50 prc): 0.65548\n",
            "========= Epoch 39 finished =========\n",
            "Training time: 0.08546\n",
            "Training loss (50 prc): 0.65545\n",
            "========= Epoch 40 finished =========\n",
            "Training time: 0.08812\n",
            "Training loss (50 prc): 0.65542\n",
            "========= Epoch 41 finished =========\n",
            "Training time: 0.094\n",
            "Training loss (50 prc): 0.65540\n",
            "========= Epoch 42 finished =========\n",
            "Training time: 0.08196\n",
            "Training loss (50 prc): 0.65537\n",
            "========= Epoch 43 finished =========\n",
            "Training time: 0.08409\n",
            "Training loss (50 prc): 0.65535\n",
            "========= Epoch 44 finished =========\n",
            "Training time: 0.08556\n",
            "Training loss (50 prc): 0.65532\n",
            "========= Epoch 45 finished =========\n",
            "Training time: 0.08214\n",
            "Training loss (50 prc): 0.65529\n",
            "========= Epoch 46 finished =========\n",
            "Training time: 0.08934\n",
            "Training loss (50 prc): 0.65527\n",
            "========= Epoch 47 finished =========\n",
            "Training time: 0.0847\n",
            "Training loss (50 prc): 0.65524\n",
            "========= Epoch 48 finished =========\n",
            "Training time: 0.08914\n",
            "Training loss (50 prc): 0.65522\n",
            "========= Epoch 49 finished =========\n",
            "Training time: 0.08604\n",
            "Training loss (50 prc): 0.65519\n",
            "========= Epoch 50 finished =========\n",
            "Training time: 0.08014\n",
            "Training loss (50 prc): 0.65516\n",
            "========= Epoch 51 finished =========\n",
            "Training time: 0.08248\n",
            "Training loss (50 prc): 0.65514\n",
            "========= Epoch 52 finished =========\n",
            "Training time: 0.08309\n",
            "Training loss (50 prc): 0.65512\n",
            "========= Epoch 53 finished =========\n",
            "Training time: 0.08132\n",
            "Training loss (50 prc): 0.65510\n",
            "========= Epoch 54 finished =========\n",
            "Training time: 0.08057\n",
            "Training loss (50 prc): 0.65507\n",
            "========= Epoch 55 finished =========\n",
            "Training time: 0.08318\n",
            "Training loss (50 prc): 0.65505\n",
            "========= Epoch 56 finished =========\n",
            "Training time: 0.08293\n",
            "Training loss (50 prc): 0.65503\n",
            "========= Epoch 57 finished =========\n",
            "Training time: 0.08126\n",
            "Training loss (50 prc): 0.65500\n",
            "========= Epoch 58 finished =========\n",
            "Training time: 0.09091\n",
            "Training loss (50 prc): 0.65498\n",
            "========= Epoch 59 finished =========\n",
            "Training time: 0.08094\n",
            "Training loss (50 prc): 0.65496\n",
            "========= Epoch 60 finished =========\n",
            "Training time: 0.09043\n",
            "Training loss (50 prc): 0.65493\n",
            "========= Epoch 61 finished =========\n",
            "Training time: 0.09157\n",
            "Training loss (50 prc): 0.65491\n",
            "========= Epoch 62 finished =========\n",
            "Training time: 0.08029\n",
            "Training loss (50 prc): 0.65489\n",
            "========= Epoch 63 finished =========\n",
            "Training time: 0.08571\n",
            "Training loss (50 prc): 0.65487\n",
            "========= Epoch 64 finished =========\n",
            "Training time: 0.08655\n",
            "Training loss (50 prc): 0.65485\n",
            "========= Epoch 65 finished =========\n",
            "Training time: 0.08154\n",
            "Training loss (50 prc): 0.65483\n",
            "========= Epoch 66 finished =========\n",
            "Training time: 0.08123\n",
            "Training loss (50 prc): 0.65481\n",
            "========= Epoch 67 finished =========\n",
            "Training time: 0.08764\n",
            "Training loss (50 prc): 0.65479\n",
            "========= Epoch 68 finished =========\n",
            "Training time: 0.08358\n",
            "Training loss (50 prc): 0.65477\n",
            "========= Epoch 69 finished =========\n",
            "Training time: 0.08487\n",
            "Training loss (50 prc): 0.65475\n",
            "========= Epoch 70 finished =========\n",
            "Training time: 0.08609\n",
            "Training loss (50 prc): 0.65473\n",
            "========= Epoch 71 finished =========\n",
            "Training time: 0.08292\n",
            "Training loss (50 prc): 0.65471\n",
            "========= Epoch 72 finished =========\n",
            "Training time: 0.09593\n",
            "Training loss (50 prc): 0.65469\n",
            "========= Epoch 73 finished =========\n",
            "Training time: 0.08586\n",
            "Training loss (50 prc): 0.65467\n",
            "========= Epoch 74 finished =========\n",
            "Training time: 0.12663\n",
            "Training loss (50 prc): 0.65465\n",
            "========= Epoch 75 finished =========\n",
            "Training time: 0.12458\n",
            "Training loss (50 prc): 0.65463\n",
            "========= Epoch 76 finished =========\n",
            "Training time: 0.12623\n",
            "Training loss (50 prc): 0.65462\n",
            "========= Epoch 77 finished =========\n",
            "Training time: 0.12747\n",
            "Training loss (50 prc): 0.65460\n",
            "========= Epoch 78 finished =========\n",
            "Training time: 0.12043\n",
            "Training loss (50 prc): 0.65458\n",
            "========= Epoch 79 finished =========\n",
            "Training time: 0.13151\n",
            "Training loss (50 prc): 0.65456\n",
            "========= Epoch 80 finished =========\n",
            "Training time: 0.11851\n",
            "Training loss (50 prc): 0.65454\n",
            "========= Epoch 81 finished =========\n",
            "Training time: 0.12671\n",
            "Training loss (50 prc): 0.65452\n",
            "========= Epoch 82 finished =========\n",
            "Training time: 0.12032\n",
            "Training loss (50 prc): 0.65451\n",
            "========= Epoch 83 finished =========\n",
            "Training time: 0.12478\n",
            "Training loss (50 prc): 0.65449\n",
            "========= Epoch 84 finished =========\n",
            "Training time: 0.12116\n",
            "Training loss (50 prc): 0.65447\n",
            "========= Epoch 85 finished =========\n",
            "Training time: 0.15204\n",
            "Training loss (50 prc): 0.65446\n",
            "========= Epoch 86 finished =========\n",
            "Training time: 0.12133\n",
            "Training loss (50 prc): 0.65444\n",
            "========= Epoch 87 finished =========\n",
            "Training time: 0.13418\n",
            "Training loss (50 prc): 0.65442\n",
            "========= Epoch 88 finished =========\n",
            "Training time: 0.12598\n",
            "Training loss (50 prc): 0.65440\n",
            "========= Epoch 89 finished =========\n",
            "Training time: 0.13478\n",
            "Training loss (50 prc): 0.65439\n",
            "========= Epoch 90 finished =========\n",
            "Training time: 0.12601\n",
            "Training loss (50 prc): 0.65437\n",
            "========= Epoch 91 finished =========\n",
            "Training time: 0.12478\n",
            "Training loss (50 prc): 0.65436\n",
            "========= Epoch 92 finished =========\n",
            "Training time: 0.10253\n",
            "Training loss (50 prc): 0.65434\n",
            "========= Epoch 93 finished =========\n",
            "Training time: 0.08553\n",
            "Training loss (50 prc): 0.65433\n",
            "========= Epoch 94 finished =========\n",
            "Training time: 0.08954\n",
            "Training loss (50 prc): 0.65431\n",
            "========= Epoch 95 finished =========\n",
            "Training time: 0.0808\n",
            "Training loss (50 prc): 0.65430\n",
            "========= Epoch 96 finished =========\n",
            "Training time: 0.07835\n",
            "Training loss (50 prc): 0.65428\n",
            "========= Epoch 97 finished =========\n",
            "Training time: 0.08509\n",
            "Training loss (50 prc): 0.65427\n",
            "========= Epoch 98 finished =========\n",
            "Training time: 0.08903\n",
            "Training loss (50 prc): 0.65425\n",
            "========= Epoch 99 finished =========\n",
            "Training time: 0.10321\n",
            "Training loss (50 prc): 0.65424\n",
            "Train finished! \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-167da06f8c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Predict on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0my_hat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ESRNN/ESRNN.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_df, decomposition)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0mY_hat_panel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat_panel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY_hat_panel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ESRNN/utils/data.py\u001b[0m in \u001b[0;36mupdate_batch_size\u001b[0;34m(self, new_batch_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_series\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ESRNN(max_epochs=25, batch_size=4, learning_rate=1e-4,\n",
        "              per_series_lr_multip=0.8, lr_scheduler_step_size=10,\n",
        "              lr_decay=0.1, gradient_clipping_threshold=50,\n",
        "              rnn_weight_decay=0.0, level_variability_penalty=100,\n",
        "              ensemble=False, max_periods=25, seasonality=[],\n",
        "              input_size=4, output_size=6,\n",
        "              cell_type='LSTM', state_hsize=40,\n",
        "              dilations=[[1], [6]], add_nl_layer=False,\n",
        "              random_seed=1, device='cpu')\n",
        "\n",
        "model.fit(x_df, y_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1LFbMtxQ-3h",
        "outputId": "e319190b-4675-4608-9f96-001eaa9bf5cc"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Infered frequency: M\n",
            "=============== Training ESRNN  ===============\n",
            "\n",
            "========= Epoch 0 finished =========\n",
            "Training time: 0.075\n",
            "Training loss (50 prc): 0.65995\n",
            "========= Epoch 1 finished =========\n",
            "Training time: 0.07643\n",
            "Training loss (50 prc): 0.65961\n",
            "========= Epoch 2 finished =========\n",
            "Training time: 0.08439\n",
            "Training loss (50 prc): 0.65927\n",
            "========= Epoch 3 finished =========\n",
            "Training time: 0.07733\n",
            "Training loss (50 prc): 0.65894\n",
            "========= Epoch 4 finished =========\n",
            "Training time: 0.0904\n",
            "Training loss (50 prc): 0.65860\n",
            "========= Epoch 5 finished =========\n",
            "Training time: 0.08376\n",
            "Training loss (50 prc): 0.65826\n",
            "========= Epoch 6 finished =========\n",
            "Training time: 0.07981\n",
            "Training loss (50 prc): 0.65792\n",
            "========= Epoch 7 finished =========\n",
            "Training time: 0.07875\n",
            "Training loss (50 prc): 0.65759\n",
            "========= Epoch 8 finished =========\n",
            "Training time: 0.08663\n",
            "Training loss (50 prc): 0.65727\n",
            "========= Epoch 9 finished =========\n",
            "Training time: 0.08123\n",
            "Training loss (50 prc): 0.65696\n",
            "========= Epoch 10 finished =========\n",
            "Training time: 0.07988\n",
            "Training loss (50 prc): 0.65666\n",
            "========= Epoch 11 finished =========\n",
            "Training time: 0.08798\n",
            "Training loss (50 prc): 0.65660\n",
            "========= Epoch 12 finished =========\n",
            "Training time: 0.08169\n",
            "Training loss (50 prc): 0.65654\n",
            "========= Epoch 13 finished =========\n",
            "Training time: 0.0837\n",
            "Training loss (50 prc): 0.65648\n",
            "========= Epoch 14 finished =========\n",
            "Training time: 0.09028\n",
            "Training loss (50 prc): 0.65641\n",
            "========= Epoch 15 finished =========\n",
            "Training time: 0.08034\n",
            "Training loss (50 prc): 0.65635\n",
            "========= Epoch 16 finished =========\n",
            "Training time: 0.09349\n",
            "Training loss (50 prc): 0.65629\n",
            "========= Epoch 17 finished =========\n",
            "Training time: 0.08551\n",
            "Training loss (50 prc): 0.65623\n",
            "========= Epoch 18 finished =========\n",
            "Training time: 0.08558\n",
            "Training loss (50 prc): 0.65617\n",
            "========= Epoch 19 finished =========\n",
            "Training time: 0.08292\n",
            "Training loss (50 prc): 0.65611\n",
            "========= Epoch 20 finished =========\n",
            "Training time: 0.08875\n",
            "Training loss (50 prc): 0.65605\n",
            "========= Epoch 21 finished =========\n",
            "Training time: 0.08402\n",
            "Training loss (50 prc): 0.65602\n",
            "========= Epoch 22 finished =========\n",
            "Training time: 0.08372\n",
            "Training loss (50 prc): 0.65598\n",
            "========= Epoch 23 finished =========\n",
            "Training time: 0.08433\n",
            "Training loss (50 prc): 0.65595\n",
            "========= Epoch 24 finished =========\n",
            "Training time: 0.08074\n",
            "Training loss (50 prc): 0.65591\n",
            "Train finished! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_df = model.predict(x_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "-gUXNZSLTsCn",
        "outputId": "0baf605d-2fa7-43a8-fd20-86d99de73fbb"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-864505e1c8b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_hat_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ESRNN/ESRNN.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_df, decomposition)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0mY_hat_panel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_hat_panel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unique_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mY_hat_panel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ESRNN/utils/data.py\u001b[0m in \u001b[0;36mupdate_batch_size\u001b[0;34m(self, new_batch_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_series\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df\n",
        "y_train_df\n",
        "\n",
        "X_train_df\n",
        "x_df['unique_id'] = X_train_df[:len(x_df)]['unique_id']\n",
        "y_df['unique_id'] = x_df['unique_id']"
      ],
      "metadata": {
        "id": "oKSzOp38QFX-"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_df\n",
        "y_df['unique_id'] = 'Y1'\n",
        "x_df['unique_id'] = 'Y1'"
      ],
      "metadata": {
        "id": "-Eq_L2xQQVXB"
      },
      "execution_count": 111,
      "outputs": []
    }
  ]
}